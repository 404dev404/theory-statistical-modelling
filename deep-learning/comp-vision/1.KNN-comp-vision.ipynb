{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from tflearn.datasets import cifar10\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Content\n",
    "____\n",
    "\n",
    "* Intro to Image Classification, data-driven approach, pipeline\n",
    "* Nearest Neighbour Classifer\n",
    "    * K-Nearest Neighbor\n",
    "* Validation sets, Cross-validation, hyperparameter tuning\n",
    "* Pros/ Cons of Nearest Neigbor\n",
    "* Summary\n",
    "* Summary : Applying KNN in Practice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example:__ For example, in the image below an image classification model takes a single image and assigns probabilities to 4 labels, {cat,dog hat, mug}. As shown in the image, keep in mind that to a computer an image is represented as one large 3-dimensional array of numbers,=. In this example, the cat image is 248 pixels wide, 400 pixels tall, and has three color channels Red,Green,Blue (or RGB for short). Therefore the image consists of 248 x 400 x 3 numbers, or a total of 297,600 numbers. Each number is an integer that ranges from 0 (black) to 255 (white). Our task is to turn this quarter of a million numbers into a single label, such as \"cat\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://cs231n.github.io/assets/classify.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The task in Image Classification is to predict a single label (or a distribution over labels as shown here to indicate our confdence) for a given image. Images are 3-dimensional arrays of integers from 0 to 255, of size Width x Height x 3. The three represents the three color channels Red, Green, Blue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges:\n",
    "\n",
    "____\n",
    "\n",
    "AS we present (an exhaustive) list of challenges below, keep in mind the raw represetation of images as a 3-D array of brightness values:\n",
    "\n",
    "* **Viewpoint Variation**: A single instance of an object can be oriented in mant ways with respect to the camera.\n",
    "\n",
    "* **Scale Variation**: Visual classes often exhibit variation in their size\n",
    "\n",
    "* **Deformation**: Many objects of interest are not rigit bodies and can be deformed in extreme ways.\n",
    "\n",
    "* **Occlusion**: the object of interest can be occuled. Sometimes only a small portion of an object could be visible.\n",
    "\n",
    "* **Illumination conditions**: The effects of illumination are drastic on the pixel level\n",
    "\n",
    "* **Background clutter**: The object of interest may blend into their enviroment, making them hard to identify. \n",
    "\n",
    "* **Intra-class variation**: The classes of interest can often be relatively voard, such as chair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighour Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our first approach, we will develop what we call a **Nearest Neighbor Classifier**. This classifier has nothing to do with Convolutional Neural Networks, and rarely is used in practice. For this example, we will use the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://cs231n.github.io/assets/nn.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose now that we are given a CIFAR-10 training set of 50,000 images. and we wish to lavel the remaining 10,000. The nearest neighor classifier will take a test image, compare it to every single one of the training images, and predict the label of the closest training image. In the image above and ont he right you can see an example result of such a procedure for 10 examples test images. Notice that in only about 3 our of the 10 examples an image of the same class in retrieved. For example, in the 8th row of the nearest training image to the horse head is a red car, presumably due to the strong black background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that we left unspecificed the details of exactly how we compare two images, which in this case are just two blocks of 32 x 32 x 3. One of the simpliest possibilities is to compare the images pixels by pixel and add up all the differences. In other words, given two images and representing them as a vector $I_1, I_2$, a reasonable choice for comparing them might be the **L1 distance**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$d_1 (I_1, I_2) = \\sum_{p} \\left| I^p_1 - I^p_2 \\right|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where the sum is taken over all pixels. Here is the procedure visualized:\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://cs231n.github.io/assets/nneg.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* An example of using pixel-wise difference to compare two images with L1 distaince. Two images are substracted elementwise and then all differences are added up to a signle number. If ywo images are identical the result will be zero. But if images are different the result will be large \n",
    "\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also look at how we might implement the classifier in code. First, let's load the CIFAR-10 data into memory as 4 arrays: the training/labels and the test/labels. In the code, ```Xtr``` (of size 50,000 x 32 x 32 x 3) holds all the images in the training set, and a corresponding 1-dimensional array ```Ytr``` (of length 50,000) holds the training labels (from 0 to 9):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading CIFAR 10, Please wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0% 170500096 / 170498071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Succesfully downloaded', 'cifar-10-python.tar.gz', 170498071, 'bytes.')\n",
      "File Extracted in Current Directory\n"
     ]
    }
   ],
   "source": [
    "(Xtr, Ytr), (Xte, Yte) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 3072)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 3072)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "print(Xtr.shape) # Returns a shape 50,000 images, 32 x 32 x 3\n",
    "Xtr_rows = Xtr.reshape(Xtr.shape[0], 32 * 32 * 3) # Reshape to 3072 \n",
    "print(Xtr_rows.shape) # Xtr_rows become 50,000 x 3072\n",
    "\n",
    "print(Xte.shape)\n",
    "Xte_rows = Xte.reshape(Xte.shape[0], 32 * 32 * 3) # Xte_rows become 10,000 x 3072\n",
    "print(Xte_rows.shape)\n",
    "print(Ytr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our NearestNeigbor Class\n",
    "\n",
    "class NearestNeigbor(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, X, y ):\n",
    "        \"\"\"X is N x D where each row is an example. Y is 1-dimension of size N\"\"\"\n",
    "        self.Xtr = X\n",
    "        self.ytr = y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"X is N x D where each row is an example we wish to predict label for\"\"\"\n",
    "        # Number of test sets 50,000\n",
    "        num_test = X.shape[0]\n",
    "        # lets make sure that the output type matches the input type\n",
    "        Ypred = np.zeros(num_test,dtype=self.ytr.dtype)\n",
    "        \n",
    "        # loop over all test rows\n",
    "        for i in range(num_test):\n",
    "            # find the nearest training image to the i'th test image\n",
    "            # using the L1 distance (sum of absolute value differences)\n",
    "            distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1)\n",
    "            min_index = np.argmin(distances)\n",
    "            Ypred[i] = self.ytr[min_index]\n",
    "        return Ypred\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NearestNeigbor()\n",
    "nn.train(Xtr_rows,Ytr)\n",
    "Yte_predict = nn.predict(Xte)\n",
    "\n",
    "print('accuracy : %f' % (np.mean(Yte_predict == Yte)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you ran this code, you would see that this classifier only achieves a __38.6%__ on CIFAR-10. That's more impressive than guessing at random, but is nowhere near human performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The choice of distance__. There are many other ways of computing distances between vectors. Another common choice could be to instead use the __L2 distance__, which has the geometric interpretation of computing the euclidean distance between two vectors. The distance takes the form:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$d_2 (I_1, I_2) = \\sqrt{\\sum_{p} \\left( I^p_1 - I^p_2 \\right)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words we would be computing the pixelwise difference as before, but this time we square all of them, add them up and finally take the square root. In numpy, using the code from above we would need to only replace a single line of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "\n",
    "distance = np.sqrt(np.sum(np.square(sel.Xtr - X[i,:]), axis = 1))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I included the ```n.sqrt``` call above, but in practical nearest neighbor application we could leave out the square root operation, because the square root is a _monotonic function_. That is, it scales the absolute sizes of the distances but preserves the ordering, so the nearest neighbors with or without it are identical. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 vs L2. It is interesting to consider differences between the two metrics. In particular the L2 distance is much more unforgiving than the L1 distance when it comes to the differences between two vectors. That is, the l2, distance perfers many medium disagreements to one big one. L1 and L2 distances are the most commonly used special cases of a p-norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K- Nearest Neigbour Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that it is strange to only use the label of the enarest image when we wish to make a prediction. Indeed, it is almost always the case that one can do better by using what's called a *K-Nearest Neighbor Classifier*. The idea is very simple, instead of finding the closest single image in the training set, we find the top k closest images, and have them vote on the label of the test image. In particular, when  k = 1, we recover the Nearest Neigbor classifier. Intuitvely, higher values of K have a smoothing effect that makes the classifier more resistant to outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://cs231n.github.io/assets/knn.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * An example of the difference between Nearest Neighbor and a 5-Nearest Neighbor classifier, using 2-dimensional points and 3 classes (red, blue, green). The colored regions show the decision boundaries induced by the classifier with an L2 distance. The white regions show points that are ambiguously classified (i.e. class votes are tied for at least two classes). Notice that in the case of a NN classifier, outlier datapoints (e.g. green point in the middle of a cloud of blue points) create small islands of likely incorrect predictions, while the 5-NN classifier smooths over these irregularities, likely leading to better generalization on the test data (not shown). Also note that the gray regions in the 5-NN image are caused by ties in the votes among the nearest neighbors (e.g. 2 neighbors are red, next two neighbors are blue, last neighbor is green).\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set for Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
